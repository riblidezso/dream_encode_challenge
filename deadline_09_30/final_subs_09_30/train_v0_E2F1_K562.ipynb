{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train E2F1 and make predictions for K562\n",
    "\n",
    "---\n",
    "\n",
    "Takes something like 10-20 minutes, and uses 50GB!\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF='E2F1'\n",
    "TRAIN_CELL_TYPES=['GM12878']\n",
    "VALID_CELL_TYPE='HeLa-S3'\n",
    "TEST_CELL_TYPE='K562'\n",
    "\n",
    "DATA_DIR='/mnt/vdisk/data/synapse/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /mnt/vdisk/data/synapse/fold_cov_data/GM12878_dnase_fold_cov.hdf in read-only mode\n",
      "Opening /mnt/vdisk/data/synapse/fold_cov_data/HeLa-S3_dnase_fold_cov.hdf in read-only mode\n",
      "Opening /mnt/vdisk/data/synapse/fold_cov_data/K562_dnase_fold_cov.hdf in read-only mode\n",
      "Opening /mnt/vdisk/data/synapse/motif_data/E2F1_motif.hdf in read-only mode\n",
      "Opening /mnt/vdisk/data/synapse/extended_labels/E2F1_labels.hdf in read-only mode\n",
      "51.5354919434 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "# load fold coverage tables for all train cell lines\n",
    "fc_train=[pd.read_hdf(DATA_DIR+'fold_cov_data/'+cl+'_dnase_fold_cov.hdf',\n",
    "                      'dnase_fold_cov')\n",
    "          for cl in TRAIN_CELL_TYPES ]\n",
    "\n",
    "#load fold coverage table for valid cell line\n",
    "fc_valid=pd.read_hdf(DATA_DIR+'fold_cov_data/'+VALID_CELL_TYPE+'_dnase_fold_cov.hdf',\n",
    "                     'dnase_fold_cov')\n",
    "\n",
    "#load fold coverage table for the final submission cell line\n",
    "fc_test=pd.read_hdf(DATA_DIR+'fold_cov_data/'+TEST_CELL_TYPE+'_dnase_fold_cov.hdf',\n",
    "                     'dnase_fold_cov')\n",
    "\n",
    "#load motif table for the transciption factor\n",
    "motif=pd.read_hdf(DATA_DIR+'motif_data/'+TF+'_motif.hdf','motif')\n",
    "          \n",
    "#load labels for the transcription factor\n",
    "labels=pd.read_hdf(DATA_DIR+'extended_labels/'+TF+'_labels.hdf','labels')\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.139111042 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "# fix index not set before\n",
    "motif.set_index(['chr1','600','800'],inplace=True)\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train,valid,test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.31047296524 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "# packing columns into the train dataset\n",
    "x_train=[fc_train[0].values,                                #cell line specific fc column\n",
    "         motif.values ] + [                                 #motif scores\n",
    "         x.values for x in fc_train[1:]] + [                #other cell line fc values\n",
    "         labels[tf].values for tf in TRAIN_CELL_TYPES[1:] ] #other cell line labels\n",
    "x_train=np.column_stack(x_train)\n",
    "y_train=labels[TRAIN_CELL_TYPES[0]].values.astype('int')\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.43988990784 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "x_valid=np.array(x_train)\n",
    "x_valid[:,0]=fc_valid.values.flatten()\n",
    "y_valid=labels[VALID_CELL_TYPE].values\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SGD logistic reg\n",
    "- it doesn't seem to use the 12 cores for most of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.963365078 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "clf = SGDClassifier(loss='log', class_weight='balanced', n_jobs=12)\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.959972829188\n",
      "32.1858530045 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "print 'auc:',roc_auc_score(y_valid,clf.predict_proba(x_valid)[:,1])\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.61988306046 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "x_test=np.array(x_train)\n",
    "x_test[:,0]=fc_test.values.flatten()\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.78429508209 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "y_test_pred=clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate predictions with the test regions\n",
    "- It has to be in the exact order of the test regions\n",
    "    - https://www.synapse.org/#!Synapse:syn6131484/wiki/402044\n",
    "- I missed the very frst line when creating the tables, I just add a 0 there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /mnt/vdisk/data/synapse//annotations/test_regions.hdf in read-only mode\n",
      "1.20881915092 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "#load index\n",
    "idx=pd.read_hdf(DATA_DIR+'/annotations/test_regions.hdf',\n",
    "                   'test_regions').index\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343874931335 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "res_df=pd.DataFrame(np.concatenate([[0],y_test_pred]),index=idx)\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The slowest part of the whole process is to write the tsv, so now i just make it in hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.90263199806 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "#slooooooooooow\n",
    "#res_df.to_csv(\n",
    "#    TF+'_test.h',sep='\\t',header=False,compression='gzip')\n",
    "\n",
    "res_df.to_hdf(TF+'_'+TEST_CELL_TYPE+'_test.hdf','preds')\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the results using shell commands\n",
    "- Not too elegant but faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.994633913 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "np.savetxt(TF+'_'+TEST_CELL_TYPE+'_test.txt',np.concatenate([[0],y_test_pred]))\n",
    "print (time.time()-start),'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " paste  <(zcat /mnt/vdisk/data/synapse//annotations/test_regions.blacklistfiltered.bed.gz ) E2F1_K562_test.txt  | gzip -c -1  > F.E2F1.K562.tab.gz\n",
      "47.4088308811 s\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "cmd = ' paste '\n",
    "cmd+= ' <(zcat '+DATA_DIR+'/annotations/test_regions.blacklistfiltered.bed.gz ) '\n",
    "cmd+= TF+'_'+TEST_CELL_TYPE +'_test.txt '\n",
    "cmd+= ' | gzip -c -1  > '+'F.'+TF+'.'+TEST_CELL_TYPE+'.tab.gz'\n",
    "print cmd\n",
    "subprocess.check_output(cmd,shell=True, executable='/bin/bash')\n",
    "\n",
    "print (time.time()-start),'s'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
